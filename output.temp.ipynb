{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c687cbc",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461f08f",
   "metadata": {
    "papermill": {
     "duration": 0.004307,
     "end_time": "2025-02-19T15:26:55.569272",
     "exception": false,
     "start_time": "2025-02-19T15:26:55.564965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extended Subgraph Partitioning (mattersim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2f7ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T15:26:55.577831Z",
     "iopub.status.busy": "2025-02-19T15:26:55.577687Z",
     "iopub.status.idle": "2025-02-19T15:26:55.582213Z",
     "shell.execute_reply": "2025-02-19T15:26:55.581915Z"
    },
    "papermill": {
     "duration": 0.009015,
     "end_time": "2025-02-19T15:26:55.582935",
     "exception": false,
     "start_time": "2025-02-19T15:26:55.573920",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill parameters\n",
    "\n",
    "supercell_scaling = [[3, 0, 0], [0, 3, 0], [0, 0, 3]]\n",
    "desired_partitions = 20\n",
    "neighborhood_distance = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e42017a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T15:26:55.590864Z",
     "iopub.status.busy": "2025-02-19T15:26:55.590424Z",
     "iopub.status.idle": "2025-02-19T15:26:55.592766Z",
     "shell.execute_reply": "2025-02-19T15:26:55.592486Z"
    },
    "papermill": {
     "duration": 0.007164,
     "end_time": "2025-02-19T15:26:55.593455",
     "exception": false,
     "start_time": "2025-02-19T15:26:55.586291",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "supercell_scaling = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21c7a2",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c0361f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T15:26:55.600820Z",
     "iopub.status.busy": "2025-02-19T15:26:55.600701Z",
     "iopub.status.idle": "2025-02-19T15:27:37.410520Z",
     "shell.execute_reply": "2025-02-19T15:27:37.409690Z"
    },
    "papermill": {
     "duration": 41.820284,
     "end_time": "2025-02-19T15:27:37.417253",
     "exception": true,
     "start_time": "2025-02-19T15:26:55.596969",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not load METIS dll: /storage/home/hcoda1/7/jshim87/local/lib/libmetis.so",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/graph_partitioning/lib/python3.11/site-packages/metis.py:430\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     _dll \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mcdll\u001b[38;5;241m.\u001b[39mLoadLibrary(_dll_filename)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/graph_partitioning/lib/python3.11/ctypes/__init__.py:454\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dlltype(name)\n",
      "File \u001b[0;32m~/.conda/envs/graph_partitioning/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: /storage/home/hcoda1/7/jshim87/local/lib/libmetis.so: undefined symbol: gk_jbufs",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpartitioner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m part_graph_extended\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n",
      "File \u001b[0;32m~/atomic-graph-partitioning/partitioner.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmetis\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpart_graph_extended\u001b[39m(G, desired_partitions, distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/graph_partitioning/lib/python3.11/site-packages/metis.py:432\u001b[0m\n\u001b[1;32m    430\u001b[0m         _dll \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mcdll\u001b[38;5;241m.\u001b[39mLoadLibrary(_dll_filename)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not load METIS dll: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m _dll_filename)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADTHEDOCS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;66;03m# Don't care if we can load the DLL on RTD.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not load METIS dll: /storage/home/hcoda1/7/jshim87/local/lib/libmetis.so"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import scrapbook as sb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from partitioner import part_graph_extended\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8802905",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Partitioning Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f7a83",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Loading a sample atomic dataset and converting it into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04a934",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "from ase.build import make_supercell\n",
    "from mattersim.datasets.utils.convertor import GraphConvertor\n",
    "from torch_geometric.utils import to_networkx\n",
    " \n",
    "atoms = read(\"datasets/test.xyz\")\n",
    "atoms = make_supercell(atoms, supercell_scaling)\n",
    "\n",
    "converter = GraphConvertor(\"m3gnet\", 5.0, True, 4.0)\n",
    "\n",
    "length = len(atoms)\n",
    "atom_graph = converter.convert(atoms.copy(), None, None, None)\n",
    "\n",
    "G = to_networkx(atom_graph)\n",
    "\n",
    "sb.glue(\"num_atoms\", len(atoms))\n",
    "print(\"Number of atoms\", len(atoms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cfaf8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Partition the computational graph into the number of desired partitions with the specified neighborhood distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396cb97",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "partitions, extended_partitions = part_graph_extended(G, desired_partitions, neighborhood_distance)\n",
    "\n",
    "num_partitions = len(partitions)\n",
    "\n",
    "print(f\"Created {num_partitions} partitions\")\n",
    "print(f\"Average partition size: {sum(len(x) for x in extended_partitions) / num_partitions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d0fe6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Create the ASE atoms object for each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c6ca3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "partitioned_atoms = []\n",
    "indices_map = [] # Table mapping each atom in each partition back to its index in the original atoms object\n",
    "\n",
    "for part in extended_partitions:\n",
    "    current_partition = []\n",
    "    current_indices_map = []\n",
    "    for atom_index in part:\n",
    "        current_partition.append(atoms[atom_index])\n",
    "        current_indices_map.append(atoms[atom_index].index)\n",
    "\n",
    "    partitioned_atoms.append(Atoms(current_partition, cell=atoms.cell, pbc=atoms.pbc)) # It's important to pass atoms.cell and atoms.pbc here\n",
    "    indices_map.append(current_indices_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4168d66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reconstructed_atoms = []\n",
    "for atom_index in range(len(atoms)):\n",
    "    reconstructed_atoms.append(atoms[atom_index])\n",
    "reconstructed_atoms = Atoms(reconstructed_atoms, cell=atoms.cell, pbc=atoms.pbc)\n",
    "\n",
    "reconstructed_atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a458b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2bfe9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f82277",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "I need to modify the M3Gnet model so that the node features can be intercepted before they are passed into the final MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d397df2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import os\n",
    "\n",
    "from mattersim.forcefield.m3gnet.m3gnet import M3Gnet\n",
    "from torch_runstats.scatter import scatter\n",
    "from mattersim.utils.download_utils import download_checkpoint\n",
    "\n",
    "class M3GnetModified(M3Gnet):\n",
    "    def forward(\n",
    "        self,\n",
    "        input: Dict[str, torch.Tensor],\n",
    "        dataset_idx: int = -1,\n",
    "    ) -> torch.Tensor:\n",
    "        # Exact data from input_dictionary\n",
    "        pos = input[\"atom_pos\"]\n",
    "        cell = input[\"cell\"]\n",
    "        pbc_offsets = input[\"pbc_offsets\"].float()\n",
    "        atom_attr = input[\"atom_attr\"]\n",
    "        edge_index = input[\"edge_index\"].long()\n",
    "        three_body_indices = input[\"three_body_indices\"].long()\n",
    "        num_three_body = input[\"num_three_body\"]\n",
    "        num_bonds = input[\"num_bonds\"]\n",
    "        num_triple_ij = input[\"num_triple_ij\"]\n",
    "        num_atoms = input[\"num_atoms\"]\n",
    "        num_graphs = input[\"num_graphs\"]\n",
    "        batch = input[\"batch\"]\n",
    "\n",
    "        # -------------------------------------------------------------#\n",
    "        cumsum = torch.cumsum(num_bonds, dim=0) - num_bonds\n",
    "        index_bias = torch.repeat_interleave(  # noqa: F501\n",
    "            cumsum, num_three_body, dim=0\n",
    "        ).unsqueeze(-1)\n",
    "        three_body_indices = three_body_indices + index_bias\n",
    "\n",
    "        # === Refer to the implementation of M3GNet,        ===\n",
    "        # === we should re-compute the following attributes ===\n",
    "        # edge_length, edge_vector(optional), triple_edge_length, theta_jik\n",
    "        atoms_batch = torch.repeat_interleave(repeats=num_atoms)\n",
    "        edge_batch = atoms_batch[edge_index[0]]\n",
    "        edge_vector = pos[edge_index[0]] - (\n",
    "            pos[edge_index[1]]\n",
    "            + torch.einsum(\"bi, bij->bj\", pbc_offsets, cell[edge_batch])\n",
    "        )\n",
    "        edge_length = torch.linalg.norm(edge_vector, dim=1)\n",
    "        vij = edge_vector[three_body_indices[:, 0].clone()]\n",
    "        vik = edge_vector[three_body_indices[:, 1].clone()]\n",
    "        rij = edge_length[three_body_indices[:, 0].clone()]\n",
    "        rik = edge_length[three_body_indices[:, 1].clone()]\n",
    "        cos_jik = torch.sum(vij * vik, dim=1) / (rij * rik)\n",
    "        # eps = 1e-7 avoid nan in torch.acos function\n",
    "        cos_jik = torch.clamp(cos_jik, min=-1.0 + 1e-7, max=1.0 - 1e-7)\n",
    "        triple_edge_length = rik.view(-1)\n",
    "        edge_length = edge_length.unsqueeze(-1)\n",
    "        atomic_numbers = atom_attr.squeeze(1).long()\n",
    "\n",
    "        # featurize\n",
    "        atom_attr = self.atom_embedding(self.one_hot_atoms(atomic_numbers))\n",
    "        edge_attr = self.rbf(edge_length.view(-1))\n",
    "        edge_attr_zero = edge_attr  # e_ij^0\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        three_basis = self.sbf(triple_edge_length, torch.acos(cos_jik))\n",
    "\n",
    "        # Main Loop\n",
    "        for idx, conv in enumerate(self.graph_conv):\n",
    "            atom_attr, edge_attr = conv(\n",
    "                atom_attr,\n",
    "                edge_attr,\n",
    "                edge_attr_zero,\n",
    "                edge_index,\n",
    "                three_basis,\n",
    "                three_body_indices,\n",
    "                edge_length,\n",
    "                num_bonds,\n",
    "                num_triple_ij,\n",
    "                num_atoms,\n",
    "            )\n",
    "\n",
    "        return atom_attr  # [batch_size]\n",
    "    \n",
    "def load_modified_from_checkpoint(\n",
    "    load_path: str = None,\n",
    "    *,\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "):\n",
    "    checkpoint_folder = os.path.expanduser(\"~/.local/mattersim/pretrained_models\")\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "    if (\n",
    "        load_path is None\n",
    "        or load_path.lower() == \"mattersim-v1.0.0-1m.pth\"\n",
    "        or load_path.lower() == \"mattersim-v1.0.0-1m\"\n",
    "    ):\n",
    "        load_path = os.path.join(checkpoint_folder, \"mattersim-v1.0.0-1M.pth\")\n",
    "        if not os.path.exists(load_path):\n",
    "            print(\n",
    "                \"The pre-trained model is not found locally, \"\n",
    "                \"attempting to download it from the server.\"\n",
    "            )\n",
    "            download_checkpoint(\n",
    "                \"mattersim-v1.0.0-1M.pth\", save_folder=checkpoint_folder\n",
    "            )\n",
    "        print(f\"Loading the pre-trained {os.path.basename(load_path)} model\")\n",
    "    elif (\n",
    "        load_path.lower() == \"mattersim-v1.0.0-5m.pth\"\n",
    "        or load_path.lower() == \"mattersim-v1.0.0-5m\"\n",
    "    ):\n",
    "        load_path = os.path.join(checkpoint_folder, \"mattersim-v1.0.0-5M.pth\")\n",
    "        if not os.path.exists(load_path):\n",
    "            print(\n",
    "                \"The pre-trained model is not found locally, \"\n",
    "                \"attempting to download it from the server.\"\n",
    "            )\n",
    "            download_checkpoint(\n",
    "                \"mattersim-v1.0.0-5M.pth\", save_folder=checkpoint_folder\n",
    "            )\n",
    "        print(f\"Loading the pre-trained {os.path.basename(load_path)} model\")\n",
    "    else:\n",
    "        print(\"Loading the model from %s\" % load_path)\n",
    "    assert os.path.exists(load_path), f\"Model file {load_path} not found\"\n",
    "\n",
    "    checkpoint = torch.load(load_path, map_location=device)\n",
    "\n",
    "    model = M3GnetModified(device=device, **checkpoint[\"model_args\"]).to(device)\n",
    "    model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782aafdf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_modified_from_checkpoint(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee8b61",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Run inference on each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce161aa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mattersim.forcefield.potential import batch_to_dict\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "aggregated_atomic_numbers = torch.zeros((len(atoms), 1), dtype=torch.float32, device=device)\n",
    "aggregated_features = torch.zeros((len(atoms), 128), dtype=torch.float32, device=device)\n",
    "\n",
    "dataloader = DataLoader([converter.convert(part.copy(), None, None, None) for part in partitioned_atoms])\n",
    "\n",
    "for part_idx, input_graph in tqdm(enumerate(dataloader), total=num_partitions):\n",
    "    input_graph = input_graph.to(device)\n",
    "    input_dict = batch_to_dict(input_graph)\n",
    "    atomic_numbers = input_dict[\"atom_attr\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feat = model.forward(input_dict)\n",
    "\n",
    "    part = partitioned_atoms[part_idx]\n",
    "    for j, node in enumerate(part):\n",
    "        original_index = indices_map[part_idx][j]\n",
    "        if original_index in partitions[part_idx]: # If the node is a root node of the partition\n",
    "            aggregated_features[original_index] = feat[j]\n",
    "            aggregated_atomic_numbers[original_index] = atomic_numbers[j]\n",
    "\n",
    "    del input_graph, input_dict, atomic_numbers, feat\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660f2ac",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "atomic_numbers = aggregated_atomic_numbers.squeeze(1).long()\n",
    "batch = torch.zeros((len(atoms)), dtype=torch.int64, device=device)\n",
    "\n",
    "energy = model.final(aggregated_features).view(-1)\n",
    "energy = model.normalizer(energy, atomic_numbers)\n",
    "energy = scatter(energy, batch, dim=0, dim_size=1)\n",
    "\n",
    "sb.glue(\"partition_energy\", energy.item())\n",
    "energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa50428",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3968a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Run the prediction on the original, unpartitioned graph to obtain a benchmark for our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c7c9a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mattersim.forcefield import MatterSimCalculator\n",
    "\n",
    "atoms.calc = MatterSimCalculator(device=device, compute_stress=False)\n",
    "benchmark_energy = atoms.get_potential_energy()\n",
    "\n",
    "sb.glue(\"benchmark_energy\", benchmark_energy.item())\n",
    "benchmark_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e88183",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f2c78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_error_abs = torch.abs(benchmark_energy - energy).item()\n",
    "energy_error_pct = torch.abs((benchmark_energy - energy) / benchmark_energy).item() * 100\n",
    "energy_error_max = torch.max(benchmark_energy - energy).item()\n",
    "\n",
    "sb.glue(\"energy_error_abs\", energy_error_abs)\n",
    "sb.glue(\"energy_error_pct\", energy_error_pct)\n",
    "sb.glue(\"energy_error_max\", energy_error_max)\n",
    "\n",
    "print(f\"Absolute error: {energy_error_abs}\")\n",
    "print(f\"Percent error: {energy_error_pct}%\")\n",
    "print(f\"Maximum error: {energy_error_max}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.06307,
   "end_time": "2025-02-19T15:27:40.762988",
   "environment_variables": {},
   "exception": true,
   "input_path": "mattersim.ipynb",
   "output_path": "output.temp.ipynb",
   "parameters": {
    "supercell_scaling": [
     [
      1,
      0,
      0
     ],
     [
      0,
      1,
      0
     ],
     [
      0,
      0,
      1
     ]
    ]
   },
   "start_time": "2025-02-19T15:26:54.699918",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}