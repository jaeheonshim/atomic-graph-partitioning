{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papermill parameters\n",
    "\n",
    "supercell_size = 2\n",
    "supercell_scaling = [[supercell_size, 0, 0], [0, supercell_size, 0], [0, 0, supercell_size]]\n",
    "desired_partitions = 20\n",
    "num_message_passing = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import scrapbook as sb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from partitioner import part_graph_extended\n",
    "import networkx as nx\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 3408,
       "encoder": "json",
       "name": "num_atoms",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "num_atoms"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of atoms 3408\n"
     ]
    }
   ],
   "source": [
    "from ase.io import read\n",
    "from ase.build import make_supercell\n",
    "from mattersim.datasets.utils.convertor import GraphConvertor\n",
    "from torch_geometric.utils import to_networkx\n",
    " \n",
    "atoms = read(\"datasets/test.xyz\")\n",
    "atoms = make_supercell(atoms, supercell_scaling)\n",
    "\n",
    "converter = GraphConvertor(\"m3gnet\", 5.0, True, 4.0)\n",
    "\n",
    "length = len(atoms)\n",
    "atom_graph = converter.convert(atoms.copy(), None, None, None)\n",
    "\n",
    "G = to_networkx(atom_graph)\n",
    "\n",
    "sb.glue(\"num_atoms\", len(atoms))\n",
    "print(\"Number of atoms\", len(atoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 20 partitions\n",
      "Average partition size: 2541.85\n"
     ]
    }
   ],
   "source": [
    "partitions, extended_partitions = part_graph_extended(G, desired_partitions, num_message_passing)\n",
    "\n",
    "num_partitions = len(partitions)\n",
    "\n",
    "print(f\"Created {num_partitions} partitions\")\n",
    "print(f\"Average partition size: {sum(len(x) for x in extended_partitions) / num_partitions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "partitioned_atoms = []\n",
    "indices_map = [] # Table mapping each atom in each partition back to its index in the original atoms object\n",
    "\n",
    "for part in extended_partitions:\n",
    "    current_partition = []\n",
    "    current_indices_map = []\n",
    "    for atom_index in part:\n",
    "        current_partition.append(atoms[atom_index])\n",
    "        current_indices_map.append(atoms[atom_index].index)\n",
    "\n",
    "    partitioned_atoms.append(Atoms(current_partition, cell=atoms.cell, pbc=atoms.pbc)) # It's important to pass atoms.cell and atoms.pbc here\n",
    "    indices_map.append(current_indices_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atoms(symbols='C880H2208Ga64S64Si192', pbc=True, cell=[[23.096664428710938, 13.334883689880371, 23.9624080657959], [-23.09648895263672, 13.334826469421387, 23.962270736694336], [3.831999856629409e-05, -26.669597625732422, 23.962278366088867]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_atoms = []\n",
    "for atom_index in range(len(atoms)):\n",
    "    reconstructed_atoms.append(atoms[atom_index])\n",
    "reconstructed_atoms = Atoms(reconstructed_atoms, cell=atoms.cell, pbc=atoms.pbc)\n",
    "\n",
    "reconstructed_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mattersim.forcefield.potential import Potential\n",
    "from ase.units import GPa\n",
    "\n",
    "class PartitionPotential(Potential):\n",
    "    def forward(\n",
    "        self,\n",
    "        input: dict[str, torch.Tensor],\n",
    "        include_forces: bool = True,\n",
    "        include_stresses: bool = True,\n",
    "        dataset_idx: int = -1,\n",
    "    ):\n",
    "        output = {}\n",
    "        if self.model_name == \"graphormer\" or self.model_name == \"geomformer\":\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            strain = torch.zeros_like(input[\"cell\"], device=self.device)\n",
    "            volume = torch.linalg.det(input[\"cell\"])\n",
    "            if include_forces is True:\n",
    "                input[\"atom_pos\"].requires_grad_(True)\n",
    "            if include_stresses is True:\n",
    "                strain.requires_grad_(True)\n",
    "                input[\"cell\"] = torch.matmul(\n",
    "                    input[\"cell\"],\n",
    "                    (torch.eye(3, device=self.device)[None, ...] + strain),\n",
    "                )\n",
    "                strain_augment = torch.repeat_interleave(\n",
    "                    strain, input[\"num_atoms\"], dim=0\n",
    "                )\n",
    "                input[\"atom_pos\"] = torch.einsum(\n",
    "                    \"bi, bij -> bj\",\n",
    "                    input[\"atom_pos\"],\n",
    "                    (torch.eye(3, device=self.device)[None, ...] + strain_augment),\n",
    "                )\n",
    "                volume = torch.linalg.det(input[\"cell\"])\n",
    "\n",
    "            energies, energies_i = self.model.forward(input, dataset_idx, return_energies_per_atom=True)\n",
    "            output[\"energies\"] = energies\n",
    "            output[\"energies_i\"] = energies_i\n",
    "\n",
    "            # Only take first derivative if only force is required\n",
    "            if include_forces is True and include_stresses is False:\n",
    "                grad_outputs: list[torch.Tensor] = [\n",
    "                    torch.ones_like(\n",
    "                        energies,\n",
    "                    )\n",
    "                ]\n",
    "                grad = torch.autograd.grad(\n",
    "                    outputs=[\n",
    "                        energies,\n",
    "                    ],\n",
    "                    inputs=[input[\"atom_pos\"]],\n",
    "                    grad_outputs=grad_outputs,\n",
    "                    create_graph=self.model.training,\n",
    "                )\n",
    "\n",
    "                # Dump out gradient for forces\n",
    "                force_grad = grad[0]\n",
    "                if force_grad is not None:\n",
    "                    forces = torch.neg(force_grad)\n",
    "                    output[\"forces\"] = forces\n",
    "\n",
    "            # Take derivatives up to second order\n",
    "            # if both forces and stresses are required\n",
    "            if include_forces is True and include_stresses is True:\n",
    "                grad_outputs: list[torch.Tensor] = [\n",
    "                    torch.ones_like(\n",
    "                        energies,\n",
    "                    )\n",
    "                ]\n",
    "                grad = torch.autograd.grad(\n",
    "                    outputs=[\n",
    "                        energies,\n",
    "                    ],\n",
    "                    inputs=[input[\"atom_pos\"], strain],\n",
    "                    grad_outputs=grad_outputs,\n",
    "                    create_graph=self.model.training,\n",
    "                )\n",
    "\n",
    "                # Dump out gradient for forces and stresses\n",
    "                force_grad = grad[0]\n",
    "                stress_grad = grad[1]\n",
    "\n",
    "                if force_grad is not None:\n",
    "                    forces = torch.neg(force_grad)\n",
    "                    output[\"forces\"] = forces\n",
    "\n",
    "                if stress_grad is not None:\n",
    "                    stresses = (\n",
    "                        1 / volume[:, None, None] * stress_grad / GPa\n",
    "                    )  # 1/GPa = 160.21766208\n",
    "                    output[\"stresses\"] = stresses\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-26 14:30:58.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmattersim.forcefield.potential\u001b[0m:\u001b[36mfrom_checkpoint\u001b[0m:\u001b[36m884\u001b[0m - \u001b[1mLoading the pre-trained mattersim-v1.0.0-1M.pth model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "potential = PartitionPotential.from_checkpoint(load_training_state=False)\n",
    "potential = potential.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from mattersim.forcefield.potential import batch_to_dict\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataloader = DataLoader([converter.convert(part.copy(), None, None, None) for part in partitioned_atoms], batch_size=1)\n",
    "\n",
    "energies_parts = np.zeros(len(atoms))\n",
    "forces_parts = np.zeros((len(atoms), 3))\n",
    "stress_parts = np.zeros((len(partitions), 3, 3))\n",
    "\n",
    "for part_idx, input_graph in tqdm(enumerate(dataloader), total=num_partitions):\n",
    "    input_graph = input_graph.to(device)\n",
    "    input_dict = batch_to_dict(input_graph)\n",
    "\n",
    "    output = potential(input_dict, include_forces=True, include_stresses=True)\n",
    "\n",
    "    energies_i = output[\"energies_i\"].detach().cpu().numpy()\n",
    "    forces = output[\"forces\"].detach().cpu().numpy()\n",
    "    stress = output[\"stresses\"].detach().cpu().numpy()\n",
    "    \n",
    "    part = partitioned_atoms[part_idx]\n",
    "    for j in range(len(part)):\n",
    "        original_index = indices_map[part_idx][j]\n",
    "        if original_index in partitions[part_idx]:\n",
    "            energies_parts[original_index] = energies_i[j]\n",
    "            forces_parts[original_index] = forces[j]\n",
    "    stress_parts[part_idx] = stress\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mattersim.forcefield.potential import batch_to_dict\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataloader = DataLoader([converter.convert(atoms.copy(), None, None, None)], batch_size=1)\n",
    "\n",
    "energy = 0\n",
    "forces = np.zeros((len(atoms), 3))\n",
    "stress = np.zeros((3, 3))\n",
    "\n",
    "for input_graph in dataloader:\n",
    "    input_graph = input_graph.to(device)\n",
    "    input_dict = batch_to_dict(input_graph)\n",
    "\n",
    "    output = potential(input_dict, include_forces=True, include_stresses=True)\n",
    "\n",
    "    energy = output[\"energies\"].detach().cpu().numpy()\n",
    "    forces = output[\"forces\"].detach().cpu().numpy()\n",
    "    stress = output[\"stresses\"].detach().cpu().numpy().reshape(3, 3)\n",
    "    \n",
    "    energy = energy[0]\n",
    "    forces = forces.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy MAE: 1.0468380551742484e-05 eV/atom\n",
      "Forces MAE: 8.11114269895377e-06 eV/Å\n",
      "Stress MAE: 9.01010038473113 GPa\n"
     ]
    }
   ],
   "source": [
    "energy_part = np.sum(energies_parts)\n",
    "stress_part = np.sum(stress_parts, axis=0)\n",
    "\n",
    "energy_mae = torch.nn.L1Loss()(torch.tensor(energy_part)/len(atoms), torch.tensor(energy)/len(atoms)).item()\n",
    "forces_mae = torch.nn.L1Loss()(torch.tensor(forces_parts), torch.tensor(forces)).item()\n",
    "stress_mae = torch.nn.L1Loss()(torch.tensor(stress_part), torch.tensor(stress)).item()\n",
    "\n",
    "print(f\"Energy MAE: {energy_mae} eV/atom\")\n",
    "print(f\"Forces MAE: {forces_mae} eV/Å\")\n",
    "print(f\"Stress MAE: {stress_mae} GPa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orb-partitioning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
